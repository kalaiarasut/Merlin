{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595fdfa8",
   "metadata": {},
   "source": [
    "## 1. Check GPU & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5264a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9749da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional dependencies\n",
    "!pip install -q albumentations tensorboard timm\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753deb1b",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive\n",
    "\n",
    "Your otolith images should be organized in Google Drive like this:\n",
    "```\n",
    "MyDrive/\n",
    "‚îî‚îÄ‚îÄ otolith_data/\n",
    "    ‚îú‚îÄ‚îÄ train/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ age_01/  (images of 1-year-old fish)\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ age_02/  (images of 2-year-old fish)\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ age_03/\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "    ‚îî‚îÄ‚îÄ val/\n",
    "        ‚îú‚îÄ‚îÄ age_01/\n",
    "        ‚îú‚îÄ‚îÄ age_02/\n",
    "        ‚îî‚îÄ‚îÄ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive mounted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c55223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è CONFIGURE YOUR DATA PATH HERE\n",
    "# Change this to match your Google Drive folder structure\n",
    "\n",
    "DATA_DIR = \"/content/drive/MyDrive/otolith_data\"  # <-- CHANGE THIS\n",
    "\n",
    "import os\n",
    "if os.path.exists(DATA_DIR):\n",
    "    print(f\"‚úÖ Found data directory: {DATA_DIR}\")\n",
    "    print(\"\\nContents:\")\n",
    "    for item in os.listdir(DATA_DIR):\n",
    "        item_path = os.path.join(DATA_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            count = sum(len(files) for _, _, files in os.walk(item_path))\n",
    "            print(f\"  üìÅ {item}/ ({count} files)\")\n",
    "else:\n",
    "    print(f\"‚ùå Directory not found: {DATA_DIR}\")\n",
    "    print(\"Please update DATA_DIR to point to your otolith images folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b5e51f",
   "metadata": {},
   "source": [
    "## 3. Define Model & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191bf806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import timm\n",
    "\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6938d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Training configuration\"\"\"\n",
    "    # Data\n",
    "    data_dir: str = \"/content/drive/MyDrive/otolith_data\"\n",
    "    image_size: int = 224\n",
    "    \n",
    "    # Model\n",
    "    model_name: str = \"efficientnet_b0\"  # Options: efficientnet_b0, efficientnet_b2, resnet50, vit_b_16\n",
    "    pretrained: bool = True\n",
    "    \n",
    "    # Training\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 50\n",
    "    lr: float = 0.0001\n",
    "    weight_decay: float = 0.01\n",
    "    \n",
    "    # Task\n",
    "    task: str = \"regression\"  # or \"classification\"\n",
    "    num_classes: int = 20  # Max age for classification\n",
    "    \n",
    "    # Output\n",
    "    output_dir: str = \"/content/drive/MyDrive/otolith_models\"\n",
    "    \n",
    "    @property\n",
    "    def device(self):\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f27b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtolithDataset(Dataset):\n",
    "    \"\"\"Dataset for otolith images with age labels\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str, split: str = \"train\", \n",
    "                 image_size: int = 224, task: str = \"regression\"):\n",
    "        self.data_dir = Path(data_dir) / split\n",
    "        self.split = split\n",
    "        self.task = task\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # Collect samples\n",
    "        self.samples = []\n",
    "        self._load_from_folders()\n",
    "        \n",
    "        # Setup transforms\n",
    "        self.transform = self._get_transforms()\n",
    "        \n",
    "        print(f\"  {split}: {len(self.samples)} images\")\n",
    "    \n",
    "    def _load_from_folders(self):\n",
    "        \"\"\"Load from folder structure: age_01/, age_02/, etc.\"\"\"\n",
    "        if not self.data_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è Directory not found: {self.data_dir}\")\n",
    "            return\n",
    "            \n",
    "        for age_folder in sorted(self.data_dir.iterdir()):\n",
    "            if not age_folder.is_dir():\n",
    "                continue\n",
    "            \n",
    "            # Extract age from folder name (e.g., \"age_05\" -> 5)\n",
    "            match = re.search(r'(\\d+)', age_folder.name)\n",
    "            if not match:\n",
    "                continue\n",
    "            age = int(match.group(1))\n",
    "            \n",
    "            # Collect all images in this folder\n",
    "            for img_path in age_folder.glob(\"*\"):\n",
    "                if img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"]:\n",
    "                    self.samples.append((str(img_path), age))\n",
    "    \n",
    "    def _get_transforms(self):\n",
    "        if self.split == \"train\":\n",
    "            return A.Compose([\n",
    "                A.Resize(self.image_size, self.image_size),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
    "                A.OneOf([\n",
    "                    A.GaussNoise(var_limit=(10, 50)),\n",
    "                    A.GaussianBlur(blur_limit=3),\n",
    "                    A.MotionBlur(blur_limit=3),\n",
    "                ], p=0.3),\n",
    "                A.OneOf([\n",
    "                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
    "                    A.CLAHE(clip_limit=2),\n",
    "                    A.Equalize(),\n",
    "                ], p=0.5),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "        else:\n",
    "            return A.Compose([\n",
    "                A.Resize(self.image_size, self.image_size),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, age = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        \n",
    "        # Apply transforms\n",
    "        transformed = self.transform(image=image)\n",
    "        image = transformed[\"image\"]\n",
    "        \n",
    "        # Prepare label\n",
    "        if self.task == \"regression\":\n",
    "            label = torch.tensor(float(age), dtype=torch.float32)\n",
    "        else:\n",
    "            label = torch.tensor(age, dtype=torch.long)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dded6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtolithAgeNet(nn.Module):\n",
    "    \"\"\"CNN for otolith age estimation using transfer learning\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"efficientnet_b0\", \n",
    "                 pretrained: bool = True, task: str = \"regression\",\n",
    "                 num_classes: int = 20):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.task = task\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load backbone\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=0  # Remove classifier\n",
    "        )\n",
    "        \n",
    "        # Get feature dimension\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, 224, 224)\n",
    "            features = self.backbone(dummy)\n",
    "            self.feature_dim = features.shape[1]\n",
    "        \n",
    "        # Build head\n",
    "        if task == \"regression\":\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(self.feature_dim, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(64, 1)\n",
    "            )\n",
    "        else:\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(self.feature_dim, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, num_classes)\n",
    "            )\n",
    "        \n",
    "        print(f\"Model: {model_name}, Features: {self.feature_dim}, Task: {task}\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        output = self.head(features)\n",
    "        if self.task == \"regression\":\n",
    "            output = output.squeeze(-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3408745",
   "metadata": {},
   "source": [
    "## 4. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91949a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        preds = outputs.detach().cpu().numpy()\n",
    "        labels_np = labels.cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels_np)\n",
    "        \n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, mae\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "    r2 = r2_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, mae, rmse, r2, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training curves\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Validation')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # MAE\n",
    "    axes[1].plot(history['train_mae'], label='Train')\n",
    "    axes[1].plot(history['val_mae'], label='Validation')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE (years)')\n",
    "    axes[1].set_title('Mean Absolute Error')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # R2\n",
    "    axes[2].plot(history['val_r2'])\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('R¬≤ Score')\n",
    "    axes[2].set_title('Validation R¬≤ Score')\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_predictions(preds, labels):\n",
    "    \"\"\"Plot predicted vs actual ages\"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(labels, preds, alpha=0.5)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    max_val = max(max(labels), max(preds))\n",
    "    plt.plot([0, max_val], [0, max_val], 'r--', label='Perfect prediction')\n",
    "    \n",
    "    plt.xlabel('Actual Age (years)')\n",
    "    plt.ylabel('Predicted Age (years)')\n",
    "    plt.title('Predicted vs Actual Age')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50686adf",
   "metadata": {},
   "source": [
    "## 5. Configure & Start Training\n",
    "\n",
    "‚ö†Ô∏è **Update the configuration below before running!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346bc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ‚ö†Ô∏è CONFIGURE YOUR TRAINING HERE\n",
    "# ============================================\n",
    "\n",
    "config = Config(\n",
    "    # Path to your data in Google Drive\n",
    "    data_dir=\"/content/drive/MyDrive/otolith_data\",  # <-- CHANGE THIS\n",
    "    \n",
    "    # Model settings\n",
    "    model_name=\"efficientnet_b0\",  # Options: efficientnet_b0, efficientnet_b2, resnet50\n",
    "    \n",
    "    # Training settings\n",
    "    batch_size=32,    # Reduce to 16 or 8 if you run out of memory\n",
    "    epochs=50,        # More epochs = better results (if not overfitting)\n",
    "    lr=0.0001,        # Learning rate\n",
    "    \n",
    "    # Image size\n",
    "    image_size=224,   # 224 for efficientnet_b0, 288 for b2\n",
    "    \n",
    "    # Where to save the model\n",
    "    output_dir=\"/content/drive/MyDrive/otolith_models\",\n",
    ")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Data: {config.data_dir}\")\n",
    "print(f\"  Model: {config.model_name}\")\n",
    "print(f\"  Epochs: {config.epochs}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "print(f\"  Device: {config.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset = OtolithDataset(config.data_dir, \"train\", config.image_size, config.task)\n",
    "val_dataset = OtolithDataset(config.data_dir, \"val\", config.image_size, config.task)\n",
    "\n",
    "if len(train_dataset) == 0:\n",
    "    raise ValueError(\"‚ùå No training images found! Check your data_dir path.\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded successfully!\")\n",
    "print(f\"   Training batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b033df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some training samples\n",
    "print(\"Sample training images:\")\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i, (img, label) in enumerate(train_dataset):\n",
    "    if i >= 8:\n",
    "        break\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    \n",
    "    # Denormalize for display\n",
    "    img_display = img.numpy().transpose(1, 2, 0)\n",
    "    img_display = img_display * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img_display = np.clip(img_display, 0, 1)\n",
    "    \n",
    "    ax.imshow(img_display)\n",
    "    ax.set_title(f\"Age: {label:.0f} years\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae83884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "print(\"Creating model...\")\n",
    "model = OtolithAgeNet(\n",
    "    model_name=config.model_name,\n",
    "    pretrained=config.pretrained,\n",
    "    task=config.task,\n",
    "    num_classes=config.num_classes\n",
    ")\n",
    "model = model.to(config.device)\n",
    "\n",
    "# Loss function\n",
    "if config.task == \"regression\":\n",
    "    criterion = nn.MSELoss()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=config.lr, \n",
    "    weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=config.epochs,\n",
    "    eta_min=config.lr / 100\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model ready! Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = Path(config.output_dir) / f\"run_{timestamp}\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Output directory: {run_dir}\")\n",
    "\n",
    "# Save config\n",
    "with open(run_dir / \"config.json\", \"w\") as f:\n",
    "    json.dump(asdict(config), f, indent=2, default=str)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ed50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "history = {\n",
    "    'train_loss': [], 'train_mae': [],\n",
    "    'val_loss': [], 'val_mae': [], 'val_rmse': [], 'val_r2': []\n",
    "}\n",
    "best_val_mae = float('inf')\n",
    "patience_counter = 0\n",
    "early_stop_patience = 10\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{config.epochs}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_mae = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, config.device\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_mae, val_rmse, val_r2, preds, labels = validate(\n",
    "        model, val_loader, criterion, config.device\n",
    "    )\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_mae'].append(train_mae)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_mae'].append(val_mae)\n",
    "    history['val_rmse'].append(val_rmse)\n",
    "    history['val_r2'].append(val_r2)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train MAE: {train_mae:.2f} years\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.2f} years\")\n",
    "    print(f\"  Val RMSE: {val_rmse:.2f} years, Val R¬≤: {val_r2:.4f}\")\n",
    "    print(f\"  LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        patience_counter = 0\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_mae': val_mae,\n",
    "            'val_r2': val_r2,\n",
    "            'config': asdict(config),\n",
    "        }, run_dir / \"checkpoint_best.pt\")\n",
    "        print(f\"  ‚úÖ New best model saved! (MAE: {val_mae:.2f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(f\"\\n‚ö†Ô∏è Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Save latest checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'history': history,\n",
    "    }, run_dir / \"checkpoint_latest.pt\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(f\"   Best Validation MAE: {best_val_mae:.2f} years\")\n",
    "print(f\"   Model saved to: {run_dir}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a8a0f",
   "metadata": {},
   "source": [
    "## 6. Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646de1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate\n",
    "checkpoint = torch.load(run_dir / \"checkpoint_best.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Final validation\n",
    "val_loss, val_mae, val_rmse, val_r2, preds, labels = validate(\n",
    "    model, val_loader, criterion, config.device\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Final Model Performance:\")\n",
    "print(f\"   MAE: {val_mae:.2f} years\")\n",
    "print(f\"   RMSE: {val_rmse:.2f} years\")\n",
    "print(f\"   R¬≤ Score: {val_r2:.4f}\")\n",
    "\n",
    "# Plot predictions\n",
    "plot_predictions(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61406b",
   "metadata": {},
   "source": [
    "## 7. Export Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX format (for production deployment)\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1, 3, config.image_size, config.image_size).to(config.device)\n",
    "\n",
    "onnx_path = run_dir / \"model.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    input_names=['image'],\n",
    "    output_names=['age'],\n",
    "    dynamic_axes={'image': {0: 'batch_size'}, 'age': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model exported to ONNX: {onnx_path}\")\n",
    "print(f\"   File size: {os.path.getsize(onnx_path) / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b662a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a summary file\n",
    "summary = {\n",
    "    \"model_name\": config.model_name,\n",
    "    \"image_size\": config.image_size,\n",
    "    \"task\": config.task,\n",
    "    \"training_epochs\": len(history['train_loss']),\n",
    "    \"best_val_mae\": float(best_val_mae),\n",
    "    \"best_val_r2\": float(max(history['val_r2'])),\n",
    "    \"train_samples\": len(train_dataset),\n",
    "    \"val_samples\": len(val_dataset),\n",
    "    \"timestamp\": timestamp,\n",
    "}\n",
    "\n",
    "with open(run_dir / \"summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\nüìÅ Saved files:\")\n",
    "for f in run_dir.iterdir():\n",
    "    print(f\"   {f.name} ({os.path.getsize(f) / 1e6:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4006ff",
   "metadata": {},
   "source": [
    "## 8. Test on Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05371ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_age(model, image_path, config):\n",
    "    \"\"\"Predict age from a single otolith image\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "    \n",
    "    transform = A.Compose([\n",
    "        A.Resize(config.image_size, config.image_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    transformed = transform(image=image)\n",
    "    image_tensor = transformed[\"image\"].unsqueeze(0).to(config.device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        predicted_age = output.item()\n",
    "    \n",
    "    return predicted_age\n",
    "\n",
    "\n",
    "# Test on an image (update path as needed)\n",
    "# test_image = \"/content/drive/MyDrive/otolith_data/val/age_05/sample.jpg\"\n",
    "# age = predict_age(model, test_image, config)\n",
    "# print(f\"Predicted age: {age:.1f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaf1afa",
   "metadata": {},
   "source": [
    "## üéâ Done!\n",
    "\n",
    "Your trained model is saved in Google Drive at:\n",
    "- `otolith_models/run_XXXXXX/checkpoint_best.pt` - Best PyTorch model\n",
    "- `otolith_models/run_XXXXXX/model.onnx` - ONNX format for production\n",
    "\n",
    "### Next Steps:\n",
    "1. Download the model files\n",
    "2. Copy them to your Ocean project's `ai-services/models/` folder\n",
    "3. Update the otolith analyzer to use the trained model\n",
    "\n",
    "### To use in your app:\n",
    "```python\n",
    "# Load and use the trained model\n",
    "import torch\n",
    "\n",
    "checkpoint = torch.load(\"models/checkpoint_best.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "age = predict_age(model, \"path/to/otolith.jpg\", config)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
